{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-D2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Drugi domaci iz masinskog ucenja.\n",
        "Milos Stanisavljevic\n",
        "Mladen Jovanovic\n",
        "Miljana Stanic"
      ],
      "metadata": {
        "id": "SYo4UQCsrPOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Za 1 zadatak ostaviti kolone:\n",
        "Na osnovu specifikacije projekta i date tabele, zakljucili smo da treba ostaviti sledece tabele:\n",
        "\n",
        "> Development data\n",
        "\n",
        "\n",
        "**W_dev**\n",
        "\n",
        "**X_s_dev**\n",
        "\n",
        "**Y_dev**\n",
        "\n",
        "**A_dev**\n",
        "\n",
        "> Test data\n",
        "\n",
        "\n",
        "**W_test**\n",
        "\n",
        "**X_s_test**\n",
        "\n",
        "**Y_test**\n",
        "\n",
        "**A_test**\n",
        "\n",
        "> Variables Name\n",
        "\n",
        "\n",
        "**W_var**\n",
        "\n",
        "**X_s_var**\n",
        "\n",
        "**A_var**\n",
        "\n",
        "# Za 1 zadatak obrisati kolone:\n",
        "\n",
        "###   *Measurments, xs*\n",
        "Na osnovu datih plot grafova zakljucili smo da P21 i P15 imaju isti plot grafik odnosno iste podatke o koloni, odakle smo zakljucili da ostavimo samo jednu, i ostavili smo P21.\n",
        "\n",
        "  > Obrisati: **P15**\n",
        "\n",
        "\n",
        "### *Pomoćni podaci (Auxiliary data):*\n",
        "\n",
        "  > Obrisati: **Flight Class**\n",
        "\n",
        "### *Health measurments:*\n",
        "\n",
        "  > Obrisati:\n",
        "\n",
        "   **fan_eff_mod**\n",
        "\n",
        "   **fan_flow_mod**\n",
        "\n",
        "   **LPC_eff_mod**\n",
        "\n",
        "   **LPC_flow_mod** \n",
        "\n",
        "   **HPC_eff_mod** \n",
        "\n",
        "   **HPC_flow_mod**\n",
        "\n"
      ],
      "metadata": {
        "id": "guADTNJNr_K_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwWZBw5A9GRN"
      },
      "outputs": [],
      "source": [
        "#Domaci 2 masinsko ucenje\n",
        "import os\n",
        "import h5py\n",
        "import time\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import math\n",
        "from functools import reduce \n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename = '/content/drive/MyDrive/MasinskoD2/N-CMAPSS_DS02-006.h5'"
      ],
      "metadata": {
        "id": "nkMicjAnHfB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d590db21-0e35-49cc-dba1-88921ef418f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "with h5py.File(filename, 'r') as hdf:\n",
        "    # Development set\n",
        "    W_dev = np.array(hdf.get('W_dev'))             # W\n",
        "    X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
        "    Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
        "    A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
        "\n",
        "    # Test set\n",
        "    W_test = np.array(hdf.get('W_test'))           # W\n",
        "    X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
        "    Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
        "    A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
        "\n",
        "    # Varnams\n",
        "    W_var = np.array(hdf.get('W_var'))\n",
        "    X_s_var = np.array(hdf.get('X_s_var'))  \n",
        "    A_var = np.array(hdf.get('A_var'))\n",
        "\n",
        "    # from np.array to list dtype U4/U5\n",
        "    W_var = list(np.array(W_var, dtype='U20'))\n",
        "    X_s_var = list(np.array(X_s_var, dtype='U20'))  \n",
        "    A_var = list(np.array(A_var, dtype='U20'))\n",
        "\n",
        "\n",
        "#print(W_test)\n",
        "# W = np.concatenate((W_dev, W_test), axis=0)  \n",
        "# X_s = np.concatenate((X_s_dev, X_s_test), axis=0)\n",
        "# Y = np.concatenate((Y_dev, Y_test), axis=0) \n",
        "# A = np.concatenate((A_dev, A_test), axis=0) \n",
        "\n",
        "#Pandas DataFrame\n",
        "df_Ad = DataFrame(data = A_dev, columns = A_var)\n",
        "df_Wd = DataFrame(data = W_dev,columns = W_var)\n",
        "df_xsd = DataFrame(data = X_s_dev,columns = X_s_var)\n",
        "\n",
        "df_A = DataFrame(data = A_test, columns = A_var)\n",
        "df_W = DataFrame(data = W_test, columns = W_var)\n",
        "df_xs = DataFrame(data = X_s_test,columns = X_s_var)\n",
        "\n",
        "df_Y_dev = DataFrame(data = Y_dev, columns = ['Rul'])\n",
        "df_Y_test = DataFrame(data = Y_test,columns = ['Rul'])\n",
        "\n",
        "df_tests = pd.concat([df_A,df_W,df_xs],axis = 1)\n",
        "del df_tests[\"P15\"]\n",
        "del df_tests[\"Fc\"]\n",
        "del df_tests[\"Ps30\"]\n",
        "print(df_tests)\n",
        "#print(df_Ad)\n",
        "# print(df_Wd)\n",
        "# print(df_xsd)\n",
        "#print(\"------------\")\n",
        "#print(df_A)\n",
        "# print(df_W)\n",
        "# print(df_xs)\n",
        "df_dev = pd.concat([df_Wd, df_xsd, df_Ad], axis=1)\n",
        "#df_dev.drop(['P15','Fc',],axis = 1)\n",
        "del df_dev[\"P15\"]\n",
        "del df_dev[\"Fc\"]\n",
        "del df_dev[\"Ps30\"]\n",
        "\n",
        "df_Y_dev.drop(df_Y_dev[(df_dev.unit != 16) & (df_dev.unit != 18) & (df_dev.unit != 20)].index, inplace=True)\n",
        "df_dev.drop(df_dev[(df_dev.unit != 16) & (df_dev.unit != 18) & (df_dev.unit != 20)].index, inplace=True)\n",
        "print(df_dev.shape)\n",
        "print(df_Y_dev.shape)\n",
        "\n",
        "# del df_tests[\"P15\"]\n",
        "# del df_tests[\"Fc\"]\n",
        "# del df_tests[\"Ps30\"]\n",
        "# df_tests.drop(df_tests[(df_tests.unit != 16) & (df_tests.unit != 18) & (df_tests.unit != 20)].index, inplace=True)\n",
        "# print(\"pg break\")\n",
        "# print(df_tests)"
      ],
      "metadata": {
        "id": "t-EszW4kxIgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6dd0c7-0cb3-4523-b379-f4c3b79219a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         unit  cycle   hs      alt      Mach        TRA          T2  \\\n",
            "0        11.0    1.0  1.0  10014.0  0.457506  77.255310  503.176696   \n",
            "1        11.0    1.0  1.0  10020.0  0.457947  77.255310  503.192949   \n",
            "2        11.0    1.0  1.0  10029.0  0.458451  77.255310  503.203187   \n",
            "3        11.0    1.0  1.0  10034.0  0.458136  77.255310  503.158580   \n",
            "4        11.0    1.0  1.0  10045.0  0.458010  77.255310  503.105629   \n",
            "...       ...    ...  ...      ...       ...        ...         ...   \n",
            "1253738  15.0   67.0  0.0  10027.0  0.382473  25.136539  497.040848   \n",
            "1253739  15.0   67.0  0.0  10022.0  0.382158  25.136539  497.035821   \n",
            "1253740  15.0   67.0  0.0  10016.0  0.381969  25.136539  497.043961   \n",
            "1253741  15.0   67.0  0.0  10010.0  0.381717  25.136539  497.047255   \n",
            "1253742  15.0   67.0  0.0  10003.0  0.381402  25.136539  497.049793   \n",
            "\n",
            "                T24          T30          T48          T50         P2  \\\n",
            "0        601.369822  1441.086963  1822.407728  1230.069061  11.636834   \n",
            "1        601.381211  1441.055436  1822.376094  1230.025551  11.637199   \n",
            "2        601.392126  1441.063188  1822.350721  1229.965758  11.636655   \n",
            "3        601.348485  1440.964145  1822.141800  1229.809741  11.632321   \n",
            "4        601.285695  1440.852510  1822.019760  1229.732630  11.626363   \n",
            "...             ...          ...          ...          ...        ...   \n",
            "1253738  544.098139  1203.357895  1421.337905  1077.482738  11.143805   \n",
            "1253739  544.035020  1203.472392  1422.772517  1078.697718  11.144114   \n",
            "1253740  544.055787  1203.507712  1422.445115  1078.410015  11.145616   \n",
            "1253741  544.060142  1203.529870  1422.576000  1078.539340  11.146680   \n",
            "1253742  544.066645  1203.566865  1422.622803  1078.589932  11.147872   \n",
            "\n",
            "               P21        P24         P40        P50           Nf  \\\n",
            "0        16.142982  20.267629  338.924861  12.659612  2165.845658   \n",
            "1        16.142833  20.267529  338.880009  12.656794  2165.802442   \n",
            "2        16.141939  20.266716  338.853562  12.653878  2165.850503   \n",
            "3        16.136395  20.260029  338.737926  12.649651  2165.818130   \n",
            "4        16.128275  20.249683  338.585509  12.644455  2165.716258   \n",
            "...            ...        ...         ...        ...          ...   \n",
            "1253738  13.032946  14.657219  177.161207  10.930024  1545.901677   \n",
            "1253739  13.031436  14.652980  177.248757  10.935884  1545.145061   \n",
            "1253740  13.033973  14.656059  177.282416  10.937328  1545.342359   \n",
            "1253741  13.035374  14.657504  177.307199  10.939893  1545.300096   \n",
            "1253742  13.037160  14.659412  177.343813  10.942771  1545.309090   \n",
            "\n",
            "                  Nc        Wf  \n",
            "0        8599.379660  3.888887  \n",
            "1        8599.261676  3.888376  \n",
            "2        8599.291842  3.887927  \n",
            "3        8599.008692  3.886111  \n",
            "4        8598.651500  3.884250  \n",
            "...              ...       ...  \n",
            "1253738  7793.390403  1.597471  \n",
            "1253739  7793.313270  1.601279  \n",
            "1253740  7793.574088  1.600758  \n",
            "1253741  7793.618063  1.601250  \n",
            "1253742  7793.743144  1.601606  \n",
            "\n",
            "[1253743 rows x 19 columns]\n",
            "(2424174, 19)\n",
            "(2424174, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "train_RNN_x = np.concatenate((df_dev.drop(df_dev[(df_dev.unit != 16)].index).to_numpy(),\n",
        "                             df_dev.drop(df_dev[(df_dev.unit != 18)].index).to_numpy(),\n",
        "                             df_dev.drop(df_dev[(df_dev.unit != 20)].index).to_numpy()), axis=0)\n",
        "                             \n",
        "train_RNN_y = np.concatenate((df_Y_dev.drop(df_Y_dev[(df_dev.unit != 16)].index).to_numpy(),\n",
        "                             df_Y_dev.drop(df_Y_dev[(df_dev.unit != 18)].index).to_numpy(),\n",
        "                             df_Y_dev.drop(df_Y_dev[(df_dev.unit != 20)].index).to_numpy()), axis=0)\n",
        "#scaling\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_RNN_x = scaler.fit_transform(train_RNN_x)\n",
        "train_RNN_y = scaler.fit_transform(train_RNN_y)\n",
        "\n",
        "train_RNN_y = train_RNN_y.flatten()\n",
        "#print(train_RNN_x, train_RNN_y, len(train_RNN_x), len(train_RNN_y), train_RNN_y.ndim)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(train_RNN_x, (-1, 6, 19))\n",
        "trainY = numpy.reshape(train_RNN_y, (-1, 6, 1))\n",
        "\n",
        "Y_test = df_Y_test.to_numpy()\n",
        "X_test = df_tests.to_numpy()\n",
        "\n",
        "#print(len(trainX), len(trainY), len(Y_test), len(X_test))\n",
        "\n",
        "#print(\"heee\")\n",
        "#print(trainX.ndim, trainY.ndim)\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=20, batch_size=32, verbose=1)\n",
        "\"\"\"\n",
        "print(\"heee\")\n",
        "\n",
        "trainY = trainY.flatten()\n",
        "trainX = trainX.flatten()\n",
        "\n",
        "print(trainX.ndim, trainY.ndim)\n",
        "\n",
        "#trainY = scaler.inverse_transform([trainY])\n",
        "#trainX = scaler.inverse_transform([trainX])\n",
        "\n",
        "trainX = numpy.reshape(trainX, (-1, 6, 19))\n",
        "trainY = numpy.reshape(trainY, (-1, 6, 1))\n",
        "X_test = numpy.reshape(X_test, (-1, 1, 19))\n",
        "Y_test = numpy.reshape(Y_test, (-1, 1, 89))\n",
        "print(len(X_test), len(Y_test))\n",
        "\n",
        "#X_test = scaler.fit_transform(X_test)\n",
        "#Y_test = scaler.fit_transform(Y_test)\n",
        "\n",
        "#trainPredict = model.predict(trainX)\n",
        "#testPredict = model.predict(X_test)\n",
        "\n",
        "_, acc = model.evaluate(X_test, Y_test,\n",
        "                            batch_size=32)\n",
        "print('Accuracy na test skupu:', acc)\n",
        "\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "Y_test = scaler.inverse_transform([Y_test])\n",
        "\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(Y_test[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "lTn3_F1a3jFz",
        "outputId": "4c6b194b-811a-4907-8b06-b0ab427efe52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12626/12626 [==============================] - 226s 17ms/step - loss: 0.0012\n",
            "Epoch 2/20\n",
            "12626/12626 [==============================] - 218s 17ms/step - loss: 1.0842e-04\n",
            "Epoch 3/20\n",
            "12626/12626 [==============================] - 213s 17ms/step - loss: 6.0922e-05\n",
            "Epoch 4/20\n",
            "12626/12626 [==============================] - 215s 17ms/step - loss: 4.2662e-05\n",
            "Epoch 5/20\n",
            "12626/12626 [==============================] - 215s 17ms/step - loss: 3.4689e-05\n",
            "Epoch 6/20\n",
            "12626/12626 [==============================] - 216s 17ms/step - loss: 2.5948e-05\n",
            "Epoch 7/20\n",
            "12626/12626 [==============================] - 218s 17ms/step - loss: 2.1405e-05\n",
            "Epoch 8/20\n",
            "12626/12626 [==============================] - 222s 18ms/step - loss: 1.9217e-05\n",
            "Epoch 9/20\n",
            "12626/12626 [==============================] - 221s 17ms/step - loss: 2.2900e-05\n",
            "Epoch 10/20\n",
            "12626/12626 [==============================] - 219s 17ms/step - loss: 1.9489e-05\n",
            "Epoch 11/20\n",
            "12626/12626 [==============================] - 220s 17ms/step - loss: 1.6496e-05\n",
            "Epoch 12/20\n",
            "12626/12626 [==============================] - 223s 18ms/step - loss: 2.7499e-05\n",
            "Epoch 13/20\n",
            "12626/12626 [==============================] - 218s 17ms/step - loss: 1.3395e-05\n",
            "Epoch 14/20\n",
            "12626/12626 [==============================] - 212s 17ms/step - loss: 1.2720e-05\n",
            "Epoch 15/20\n",
            "12626/12626 [==============================] - 214s 17ms/step - loss: 1.3111e-05\n",
            "Epoch 16/20\n",
            "12626/12626 [==============================] - 225s 18ms/step - loss: 1.0212e-05\n",
            "Epoch 17/20\n",
            "12626/12626 [==============================] - 229s 18ms/step - loss: 9.0797e-06\n",
            "Epoch 18/20\n",
            "12626/12626 [==============================] - 223s 18ms/step - loss: 8.1162e-06\n",
            "Epoch 19/20\n",
            "12626/12626 [==============================] - 224s 18ms/step - loss: 9.7509e-06\n",
            "Epoch 20/20\n",
            "12626/12626 [==============================] - 228s 18ms/step - loss: 8.9896e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"heee\")\\n\\ntrainY = trainY.flatten()\\ntrainX = trainX.flatten()\\n\\nprint(trainX.ndim, trainY.ndim)\\n\\n#trainY = scaler.inverse_transform([trainY])\\n#trainX = scaler.inverse_transform([trainX])\\n\\ntrainX = numpy.reshape(trainX, (-1, 6, 19))\\ntrainY = numpy.reshape(trainY, (-1, 6, 1))\\nX_test = numpy.reshape(X_test, (-1, 1, 19))\\nY_test = numpy.reshape(Y_test, (-1, 1, 89))\\nprint(len(X_test), len(Y_test))\\n\\n#X_test = scaler.fit_transform(X_test)\\n#Y_test = scaler.fit_transform(Y_test)\\n\\n#trainPredict = model.predict(trainX)\\n#testPredict = model.predict(X_test)\\n\\n_, acc = model.evaluate(X_test, Y_test,\\n                            batch_size=32)\\nprint(\\'Accuracy na test skupu:\\', acc)\\n\\n# invert predictions\\ntrainPredict = scaler.inverse_transform(trainPredict)\\ntrainY = scaler.inverse_transform([trainY])\\ntestPredict = scaler.inverse_transform(testPredict)\\nY_test = scaler.inverse_transform([Y_test])\\n\\n# calculate root mean squared error\\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\\nprint(\\'Train Score: %.2f RMSE\\' % (trainScore))\\ntestScore = math.sqrt(mean_squared_error(Y_test[0], testPredict[:,0]))\\nprint(\\'Test Score: %.2f RMSE\\' % (testScore))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " prosečna kvadratna greška (RMSE) i NASA-ina funkcija bodovanja"
      ],
      "metadata": {
        "id": "b69X0-l86e2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def delta1(k):\n",
        "#   return y(k) - y1(k)\n",
        "\n",
        "# def delta2(k):\n",
        "#   return math.exp(abs(y(k) - y1(k))*1/13)\n",
        "\n",
        "# def sum1(mv, k):\n",
        "#   sum = 0\n",
        "#   deltak = map(delta1, k)\n",
        "#   sum = reduce(lambda x, y:x+y, deltak)\n",
        "#   return sum\n",
        "\n",
        "# def sum2(mv, k):\n",
        "#   sum = 0\n",
        "#   deltak = map(delta2, k)\n",
        "#   sum = reduce(lambda x, y:x+y, deltak) - 1\n",
        "#   return sum\n",
        "\n",
        "# def RMSE(mv, k):\n",
        "#   return math.sqrt(1/mv * sum1(mv, k))\n",
        "\n",
        "# def sc(mv, k):\n",
        "#   return 1/mv * sum2(mv, k)\n",
        "\n",
        "# score = 0.5 * RMSE(mv, k) + 0.5 * sc(mv, k)\n",
        "# trainY = trainY.flatten()\n",
        "# trainX = trainX.flatten()\n",
        "\n",
        "# print(trainX.ndim, trainY.ndim)\n",
        "\n",
        "# trainY = scaler.inverse_transform([trainY])\n",
        "# trainX = scaler.inverse_transform([trainX])\n",
        "\n",
        "# #trainPredict = model.predict(trainX)\n",
        "# testPredict = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "def delta1(k):\n",
        "  return (Y_test[k] - testPredict[k]) ** 2\n",
        "\n",
        "def delta2(k):\n",
        "  alfa = Y_test(k) - testPredict(k)\n",
        "  if (alfa > 0):\n",
        "    return (abs(alfa))*1/10)\n",
        "  else:\n",
        "    return (abs(alfa))*1/13)\n",
        "\n",
        "def sum1(mv):\n",
        "  sum = 0\n",
        "  for k in range(mv):\n",
        "    sum = sum + delta1(k)\n",
        "  return sum\n",
        "\n",
        "def sum2(mv,alfa):\n",
        "  sum = 0\n",
        "  for k in mv:\n",
        "    sum = sum + (math.exp(delta2(k))-1)\n",
        "  return sum\n",
        "\n",
        "def RMSE(mv):\n",
        "  return math.sqrt(1/mv*sum1(mv))\n",
        "\n",
        "def sc(mv, k):\n",
        "  return 1/mv * sum2(mv, alfa)\n",
        "\n",
        "alfa = 1/13\n",
        "mv = len(Y_test)\n",
        "#gde mv predstavlja broj primera u skupu podataka za validaciju\n",
        "score = 0.5 * RMSE(mv) + 0.5 * sc(mv, alfa)"
      ],
      "metadata": {
        "id": "gnz7XVYT6l2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "7009b03c-44cb-45f4-d25d-80ba25c1308a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 6, 19) for input KerasTensor(type_spec=TensorSpec(shape=(None, 6, 19), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, None).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-07e9916272a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#trainPredict = model.predict(trainX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, None), dtype=float32)\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    }
  ]
}